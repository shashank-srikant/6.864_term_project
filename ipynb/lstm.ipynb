{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pickled data...\n",
      "elapsed time: 27.56 sec\n",
      "RNN (\n",
      "  (embedding_layer): Embedding(100406, 200)\n",
      "  (lstm): LSTM(200, 240, batch_first=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import ConfigParser\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import cPickle as pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from ranking_metrics import compute_mrr, precision_at_k, compute_map\n",
    "\n",
    "np.random.seed(0)\n",
    "#torch.manual_seed(0)\n",
    "\n",
    "config = ConfigParser.ConfigParser()\n",
    "config.readfp(open(r'../src/config.ini'))\n",
    "\n",
    "SAVE_PATH = config.get('paths', 'save_path')\n",
    "DATA_FILE_NAME = config.get('paths', 'extracted_data_file_name')\n",
    "TRAIN_TEST_FILE_NAME = config.get('paths', 'train_test_file_name')\n",
    "SAVE_NAME = config.get('rnn_params', 'save_name')\n",
    "NUM_NEGATIVE = int(config.get('data_params', 'NUM_NEGATIVE')) \n",
    "\n",
    "MAX_TITLE_LEN = int(config.get('data_params', 'MAX_TITLE_LEN'))\n",
    "MAX_BODY_LEN = int(config.get('data_params', 'MAX_BODY_LEN'))\n",
    "\n",
    "data_filename = SAVE_PATH + DATA_FILE_NAME\n",
    "train_test_filename = SAVE_PATH + TRAIN_TEST_FILE_NAME\n",
    "\n",
    "print \"loading pickled data...\"\n",
    "tic = time()\n",
    "with open(data_filename) as f:  \n",
    "    train_text_df, train_idx_df, dev_idx_df, test_idx_df, embeddings, word_to_idx = pickle.load(f)\n",
    "f.close()\n",
    "with open(train_test_filename) as f:\n",
    "    train_data, val_data, test_data = pickle.load(f)\n",
    "f.close()\n",
    "toc = time()\n",
    "print \"elapsed time: %.2f sec\" %(toc - tic)\n",
    "\n",
    "\n",
    "#visualize data\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "sns.distplot(train_text_df['title_len'], hist=True, kde=True, color='b', label='title len', ax=ax1)\n",
    "sns.distplot(train_text_df[train_text_df['body_len'] < 256]['body_len'], hist=True, kde=True, color='r', label='body len', ax=ax2)\n",
    "ax1.axvline(x=MAX_TITLE_LEN, color='k', linestyle='--', label='max len')\n",
    "ax2.axvline(x=MAX_BODY_LEN, color='k', linestyle='--', label='max len')\n",
    "ax1.set_title('title length histogram'); ax1.legend(loc=1); \n",
    "ax2.set_title('body length histogram'); ax2.legend(loc=1);\n",
    "plt.savefig('../figures/question_len_hist.png')\n",
    "\n",
    "#training parameters\n",
    "num_epochs = 2 #16 \n",
    "batch_size = 1 \n",
    "\n",
    "#model parameters\n",
    "embed_dim = embeddings.shape[1] #200\n",
    "hidden_size = 240 #number of LSTM cells \n",
    "weight_decay = 1e-5 \n",
    "learning_rate = 1e-3\n",
    "\n",
    "#RNN architecture\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_dim, hidden_size, vocab_size, batch_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        #TODO: ignore loss computations on 0 embedding index inputs \n",
    "        #TODO: average pooling\n",
    "        #TODO: display gradient magnitude\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embed_dim) \n",
    "        self.embedding_layer.weight.data = torch.from_numpy(embeddings)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_size, num_layers=1, batch_first=True)\n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        #[num_layers, batch_size, hidden_size] for (h_n, c_n)\n",
    "        return (Variable(torch.zeros(1, self.batch_size, self.hidden_size)),\n",
    "                Variable(torch.zeros(1, self.batch_size, self.hidden_size)))\n",
    "\n",
    "    def forward(self, x_idx):\n",
    "        all_x = self.embedding_layer(x_idx)\n",
    "        #[batch_size, seq_length (num_words), embed_dim]\n",
    "        lstm_out, self.hidden = self.lstm(all_x.view(self.batch_size, x_idx.size(1), -1), self.hidden)\n",
    "        #h_n dim: [1, batch_size, hidden_size]\n",
    "        h_n, c_n = self.hidden[0], self.hidden[1]\n",
    "        return h_n.squeeze(0) \n",
    "        \n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "model = RNN(embed_dim, hidden_size, len(word_to_idx), batch_size)\n",
    "if use_gpu:\n",
    "    print \"found CUDA GPU...\"\n",
    "    model = model.cuda()\n",
    "    \n",
    "print model\n",
    "\n",
    "#define loss and optimizer\n",
    "criterion = nn.MultiMarginLoss(p=1, margin=0.4, size_average=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = StepLR(optimizer, step_size=4, gamma=0.5) #half learning rate every 4 epochs\n",
    "\n",
    "learning_rate_schedule = [] \n",
    "training_loss, validation_loss, test_loss = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100407, 200])\n",
      "torch.Size([100407, 200])\n",
      "torch.Size([960, 200])\n",
      "torch.Size([960, 200])\n",
      "torch.Size([960, 240])\n",
      "torch.Size([960, 240])\n",
      "torch.Size([960])\n",
      "torch.Size([960])\n",
      "424320\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for i in model.parameters():\n",
    "    ss = 1\n",
    "    for j in i.data.shape:\n",
    "        print i.data.shape\n",
    "        ss = ss*j\n",
    "    s = ss+s\n",
    "print str(s - (100407*200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"training...\"\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    running_train_loss = 0.0\n",
    "    \n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_data, \n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "        num_workers = 4, \n",
    "        drop_last = True)\n",
    "        \n",
    "    model.train()\n",
    "    scheduler.step()\n",
    "        \n",
    "    for batch in tqdm(train_data_loader):\n",
    "      \n",
    "        query_title = Variable(batch['query_title'])\n",
    "        query_body = Variable(batch['query_body'])\n",
    "        similar_title = Variable(batch['similar_title'])\n",
    "        similar_body = Variable(batch['similar_body'])\n",
    "\n",
    "        random_title_list = []\n",
    "        random_body_list = []\n",
    "        for ridx in range(NUM_NEGATIVE): #100, number of random (negative) examples \n",
    "            random_title_name = 'random_title_' + str(ridx)\n",
    "            random_body_name = 'random_body_' + str(ridx)\n",
    "            random_title_list.append(Variable(batch[random_title_name]))\n",
    "            random_body_list.append(Variable(batch[random_body_name]))\n",
    "\n",
    "        if use_gpu:\n",
    "            query_title, query_body = query_title.cuda(), query_body.cuda()\n",
    "            similar_title, similar_body = similar_title.cuda(), similar_body.cuda()\n",
    "            random_title_list = map(lambda item: item.cuda(), random_title_list)\n",
    "            random_body_list = map(lambda item: item.cuda(), random_body_list)\n",
    "        \n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        #query title\n",
    "        model.hidden = model.init_hidden() \n",
    "        if use_gpu:\n",
    "            model.hidden = tuple(map(lambda item: item.cuda(), model.hidden))\n",
    "        lstm_query_title = model(query_title)\n",
    "\n",
    "        #query body\n",
    "        model.hidden = model.init_hidden() \n",
    "        if use_gpu:\n",
    "            model.hidden = tuple(map(lambda item: item.cuda(), model.hidden))\n",
    "        lstm_query_body = model(query_body)\n",
    "\n",
    "        lstm_query = (lstm_query_title + lstm_query_body)/2.0\n",
    "\n",
    "        #similar title\n",
    "        model.hidden = model.init_hidden() \n",
    "        if use_gpu:\n",
    "            model.hidden = tuple(map(lambda item: item.cuda(), model.hidden))\n",
    "        lstm_similar_title = model(similar_title)\n",
    "\n",
    "        #similar body\n",
    "        model.hidden = model.init_hidden() \n",
    "        if use_gpu:\n",
    "            model.hidden = tuple(map(lambda item: item.cuda(), model.hidden))\n",
    "        lstm_similar_body = model(similar_body)\n",
    "\n",
    "        lstm_similar = (lstm_similar_title + lstm_similar_body)/2.0\n",
    "\n",
    "        lstm_random_list = []\n",
    "        for ridx in range(len(random_title_list)):\n",
    "            #random title\n",
    "            model.hidden = model.init_hidden() \n",
    "            if use_gpu:\n",
    "                model.hidden = tuple(map(lambda item: item.cuda(), model.hidden))\n",
    "            lstm_random_title = model(random_title_list[ridx])\n",
    "\n",
    "            #random body\n",
    "            model.hidden = model.init_hidden() \n",
    "            if use_gpu:\n",
    "                model.hidden = tuple(map(lambda item: item.cuda(), model.hidden))\n",
    "            lstm_random_body = model(random_body_list[ridx])\n",
    "\n",
    "            lstm_random = (lstm_random_title + lstm_random_body)/2.0\n",
    "            lstm_random_list.append(lstm_random)\n",
    "        #end for\n",
    "           \n",
    "        cosine_similarity = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        score_pos = cosine_similarity(lstm_query, lstm_similar)\n",
    "\n",
    "        score_list = []\n",
    "        score_list.append(score_pos)\n",
    "        for ridx in range(len(lstm_random_list)):\n",
    "            score_neg = cosine_similarity(lstm_query, lstm_random_list[ridx])\n",
    "            score_list.append(score_neg)\n",
    "\n",
    "        X_scores = torch.stack(score_list, 1) #[batch_size, K=101]\n",
    "        y_targets = Variable(torch.zeros(X_scores.size(0)).type(torch.LongTensor)) #[batch_size]\n",
    "        if use_gpu:\n",
    "            y_targets = y_targets.cuda()\n",
    "        loss = criterion(X_scores, y_targets) #y_target=0\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        running_train_loss += loss.cpu().data[0]        \n",
    "        \n",
    "    #end for\n",
    "    training_loss.append(running_train_loss)\n",
    "    learning_rate_schedule.append(scheduler.get_lr())\n",
    "    print \"epoch: %4d, training loss: %.4f\" %(epoch+1, running_train_loss)\n",
    "    \n",
    "    torch.save(model, SAVE_PATH + SAVE_NAME)\n",
    "\n",
    "    #early stopping\n",
    "    patience = 4\n",
    "    min_delta = 0.1\n",
    "    if epoch == 0:\n",
    "        patience_cnt = 0\n",
    "    elif epoch > 0 and training_loss[epoch-1] - training_loss[epoch] > min_delta:\n",
    "        patience_cnt = 0\n",
    "    else:\n",
    "        patience_cnt += 1\n",
    "\n",
    "    if patience_cnt > patience:\n",
    "        print \"early stopping...\"\n",
    "        break\n",
    "#end for\n",
    "\"\"\"\n",
    "print \"loading pre-trained model...\"\n",
    "model = torch.load(SAVE_PATH + SAVE_NAME)\n",
    "if use_gpu:\n",
    "    print \"found CUDA GPU...\"\n",
    "    model = model.cuda()\n",
    "\"\"\"\n",
    "\n",
    "print \"scoring test questions...\"\n",
    "running_test_loss = 0.0\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_data, \n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    num_workers = 4, \n",
    "    drop_last = True)\n",
    "        \n",
    "model.eval()\n",
    "\n",
    "for batch in tqdm(test_data_loader):\n",
    "\n",
    "    query_idx = batch['query_idx']\n",
    "    query_title = Variable(batch['query_title'])\n",
    "    query_body = Variable(batch['query_body'])\n",
    "    similar_title = Variable(batch['similar_title'])\n",
    "    similar_body = Variable(batch['similar_body'])\n",
    "\n",
    "    random_title_list = []\n",
    "    random_body_list = []\n",
    "    for ridx in range(20): #number of retrieved (bm25) examples \n",
    "        random_title_name = 'random_title_' + str(ridx)\n",
    "        random_body_name = 'random_body_' + str(ridx)\n",
    "        random_title_list.append(Variable(batch[random_title_name]))\n",
    "        random_body_list.append(Variable(batch[random_body_name]))\n",
    "\n",
    "    if use_gpu:\n",
    "        query_title, query_body = query_title.cuda(), query_body.cuda()\n",
    "        similar_title, similar_body = similar_title.cuda(), similar_body.cuda()\n",
    "        random_title_list = map(lambda item: item.cuda(), random_title_list)\n",
    "        random_body_list = map(lambda item: item.cuda(), random_body_list)\n",
    "\n",
    "    #query title\n",
    "    model.hidden = model.init_hidden() \n",
    "    if use_gpu:\n",
    "        model.hidden = tuple(map(lambda item: item.cuda(), model.hidden))\n",
    "    lstm_query_title = model(query_title)\n",
    "\n",
    "    #query body\n",
    "    model.hidden = model.init_hidden() \n",
    "    if use_gpu:\n",
    "        model.hidden = tuple(map(lambda item: item.cuda(), model.hidden))\n",
    "    lstm_query_body = model(query_body)\n",
    "\n",
    "    lstm_query = (lstm_query_title + lstm_query_body)/2.0\n",
    "\n",
    "    #similar title\n",
    "    model.hidden = model.init_hidden() \n",
    "    if use_gpu:\n",
    "        model.hidden = tuple(map(lambda item: item.cuda(), model.hidden))\n",
    "    lstm_similar_title = model(similar_title)\n",
    "\n",
    "    #similar body\n",
    "    model.hidden = model.init_hidden() \n",
    "    if use_gpu:\n",
    "        model.hidden = tuple(map(lambda item: item.cuda(), model.hidden))\n",
    "    lstm_similar_body = model(similar_body)\n",
    "\n",
    "    lstm_similar = (lstm_similar_title + lstm_similar_body)/2.0\n",
    "\n",
    "    lstm_random_list = []\n",
    "    for ridx in range(len(random_title_list)):\n",
    "        #random title\n",
    "        model.hidden = model.init_hidden() \n",
    "        if use_gpu:\n",
    "            model.hidden = tuple(map(lambda item: item.cuda(), model.hidden))\n",
    "        lstm_random_title = model(random_title_list[ridx])\n",
    "\n",
    "        #random body\n",
    "        model.hidden = model.init_hidden() \n",
    "        if use_gpu:\n",
    "            model.hidden = tuple(map(lambda item: item.cuda(), model.hidden))\n",
    "        lstm_random_body = model(random_body_list[ridx])\n",
    "\n",
    "        lstm_random = (lstm_random_title + lstm_random_body)/2.0\n",
    "        lstm_random_list.append(lstm_random)\n",
    "    #end for\n",
    "           \n",
    "    cosine_similarity = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    score_pos = cosine_similarity(lstm_query, lstm_similar)\n",
    "\n",
    "    score_list = []\n",
    "    score_list.append(score_pos)\n",
    "    for ridx in range(len(lstm_random_list)):\n",
    "        score_neg = cosine_similarity(lstm_query, lstm_random_list[ridx])\n",
    "        score_list.append(score_neg)\n",
    "\n",
    "    X_scores = torch.stack(score_list, 1) #[batch_size, K=101]\n",
    "    y_targets = Variable(torch.zeros(X_scores.size(0)).type(torch.LongTensor)) #[batch_size]\n",
    "    if use_gpu:\n",
    "        y_targets = y_targets.cuda()\n",
    "    loss = criterion(X_scores, y_targets) #y_target=0\n",
    "    running_test_loss += loss.cpu().data[0]        \n",
    "    \n",
    "    #save scores to data frame\n",
    "    lstm_query_idx = query_idx.cpu().numpy()\n",
    "    lstm_retrieved_scores = X_scores.cpu().data.numpy()[:,1:] #skip positive score\n",
    "    for row, qidx in enumerate(lstm_query_idx):\n",
    "        test_idx_df.loc[test_idx_df['query_id'] == qidx, 'lstm_score'] = \" \".join(lstm_retrieved_scores[row,:].astype('str'))\n",
    "#end for        \n",
    "    \n",
    "print \"total test loss: \", running_test_loss\n",
    "print \"number of NaN: \\n\", test_idx_df.isnull().sum()\n",
    "test_idx_df = test_idx_df.dropna() #NaNs are due to restriction: range(100)\n",
    "\n",
    "#save scored data frame\n",
    "test_idx_df.to_csv(SAVE_PATH + '/test_idx_df_scored_lstm.csv', header=True)\n",
    "\n",
    "print \"computing ranking metrics...\"\n",
    "lstm_mrr_test = compute_mrr(test_idx_df, score_name='lstm_score')\n",
    "print \"lstm MRR (test): \", np.mean(lstm_mrr_test)\n",
    "\n",
    "lstm_pr1_test = precision_at_k(test_idx_df, K=1, score_name='lstm_score')\n",
    "print \"lstm P@1 (test): \", np.mean(lstm_pr1_test)\n",
    "\n",
    "lstm_pr5_test = precision_at_k(test_idx_df, K=5, score_name='lstm_score')\n",
    "print \"lstm P@5 (test): \", np.mean(lstm_pr5_test)\n",
    "\n",
    "lstm_map_test = compute_map(test_idx_df, score_name='lstm_score')\n",
    "print \"lstm map (test): \", np.mean(lstm_map_test)\n",
    "\n",
    "\n",
    "#generate plots\n",
    "plt.figure()\n",
    "plt.plot(training_loss, label='Adam')\n",
    "plt.title(\"LSTM Model Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.savefig('../figures/lstm_training_loss.png')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(learning_rate_schedule, label='learning rate')\n",
    "plt.title(\"LSTM learning rate schedule\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning rate\")\n",
    "plt.legend()\n",
    "plt.savefig('../figures/lstm_learning_rate_schedule.png')\n",
    "\n",
    "\"\"\"\n",
    "plt.figure()\n",
    "plt.plot(validation_loss, label='Adam')\n",
    "plt.title(\"LSTM Model Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.savefig('./figures/lstm_validation_loss.png')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle as pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "####\n",
    "import os\n",
    "from os.path import dirname, realpath\n",
    "import sys\n",
    "sys.path.append(dirname(os.getcwd()))\n",
    "import nltk as nk\n",
    "from nltk.corpus import stopwords\n",
    "import dill\n",
    "import ConfigParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = ConfigParser.ConfigParser()\n",
    "config.readfp(open(r'../src/config.ini'))\n",
    "SAVE_PATH = config.get('paths', 'save_path')\n",
    "TRAIN_TEST_FILE_NAME = \"data_train_test_100.dat\"\n",
    "filename = SAVE_PATH + TRAIN_TEST_FILE_NAME\n",
    "with open(filename) as f:  # Python 3: open(..., 'rb')\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "DATA_FILE_NAME = config.get('paths', 'extracted_data_file_name')\n",
    "filename = SAVE_PATH + DATA_FILE_NAME\n",
    "\n",
    "tic1 = time()\n",
    "with open(filename) as f:  # Python 3: open(..., 'rb')\n",
    "    train_text_df, train_idx_df, dev_idx_df, embeddings, word_to_idx = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train_text_df\n",
    "del train_idx_df\n",
    "del dev_idx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class  CNN(nn.Module):\n",
    "    def __init__(self, embed_num, embed_dim, kernel_num, kernel_sizes):\n",
    "        super(CNN,self).__init__()\n",
    "        V = embed_num\n",
    "        D = embed_dim\n",
    "        Ci = 1\n",
    "        Co = kernel_num\n",
    "        Ks = kernel_sizes\n",
    "\n",
    "        self.embed = nn.Embedding(V, D)\n",
    "        self.embed.weight.data = torch.from_numpy(embeddings)\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])\n",
    "        #self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3) #(N,Co,W)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print \"begin: \"+str(x.size())\n",
    "        x = self.embed(x) # (N,W,D)\n",
    "        #print \"after embedding: \"+ str(x.size())\n",
    "        #if self.args.static:\n",
    "        #    x = Variable(x)\n",
    "\n",
    "        x = x.unsqueeze(1) # (N,Ci,W,D)\n",
    "        #print \"after unsqueeze: \"+ str(x.size())\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1] #[(N,Co,W), ...]*len(Ks)\n",
    "        #print x\n",
    "        #print \"after relu: \"+ str(len(x)) + \"::\" + str(x[0].size())+ \"::\" + str(x[1].size())\n",
    "\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x] #[(N,Co), ...]*len(Ks)\n",
    "        #print x\n",
    "        #print \"after max_pool1d: \"+ str(len(x)) + \"::\" + str(x[0].size())+ \"::\" + str(x[1].size())\n",
    "        \n",
    "        x = torch.cat(x, 1)\n",
    "        #print \"after torch cat final step: \"+ str(x.size())\n",
    "        #print \"---\"\n",
    "        #sys.exit(0)\n",
    "        #x = self.dropout(x) # (N,len(Ks)*Co)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN (\n",
      "  (embed): Embedding(100406, 200)\n",
      "  (convs1): ModuleList (\n",
      "    (0): Conv2d(1, 100, kernel_size=(3, 200), stride=(1, 1))\n",
      "    (1): Conv2d(1, 100, kernel_size=(4, 200), stride=(1, 1))\n",
      "    (2): Conv2d(1, 100, kernel_size=(5, 200), stride=(1, 1))\n",
      "    (3): Conv2d(1, 100, kernel_size=(6, 200), stride=(1, 1))\n",
      "    (4): Conv2d(1, 100, kernel_size=(7, 200), stride=(1, 1))\n",
      "    (5): Conv2d(1, 100, kernel_size=(8, 200), stride=(1, 1))\n",
      "    (6): Conv2d(1, 100, kernel_size=(9, 200), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "embed_num = len(word_to_idx)\n",
    "embed_dim = len(embeddings[0])\n",
    "kernel_num = 100\n",
    "kernel_sizes = range(3,10)\n",
    "batch_size = 50\n",
    "model = CNN(embed_num, embed_dim, kernel_num, kernel_sizes)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e2\n",
    "print model\n",
    "\n",
    "#define loss and optimizer\n",
    "criterion = nn.MultiMarginLoss(p=1, margin=2, size_average=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "::batch begin::\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print \"training...\"\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    running_train_loss = 0.0\n",
    "    \n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_data, \n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "        num_workers = 4, \n",
    "        drop_last = True)\n",
    "        \n",
    "    model.train()\n",
    "    count_batch = 0    \n",
    "    for batch in train_data_loader:\n",
    "        count_batch += 1\n",
    "        print \"::batch begin::\"\n",
    "        query_title = Variable(batch['query_title'])\n",
    "        query_body = Variable(batch['query_body'])\n",
    "        similar_title = Variable(batch['similar_title'])\n",
    "        similar_body = Variable(batch['similar_body'])\n",
    "        \n",
    "        random_title_list = []\n",
    "        random_body_list = []\n",
    "        for ridx in range(10):  #range(100)\n",
    "            random_title_name = 'random_title_' + str(ridx)\n",
    "            random_body_name = 'random_body_' + str(ridx)\n",
    "            random_title_list.append(Variable(batch[random_title_name]))\n",
    "            random_body_list.append(Variable(batch[random_body_name]))\n",
    "        \n",
    "        if count_batch  == 1:\n",
    "            break\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        print \"::query title::\" \n",
    "        lstm_query_title = model(query_title)\n",
    "        print \"::query body::\" \n",
    "        lstm_query_body = model(query_body)\n",
    "        lstm_query = (lstm_query_title + lstm_query_body)/2.0\n",
    "        \n",
    "        print \"::query similar title::\" \n",
    "        lstm_similar_title = model(similar_title)\n",
    "        print \"::query similar body::\" \n",
    "        lstm_similar_body = model(similar_body)\n",
    "        lstm_similar = (lstm_similar_title + lstm_similar_body)/2.0\n",
    "        \n",
    "        \n",
    "        lstm_random_list = []\n",
    "        print \"::random title body process::\" \n",
    "        \n",
    "        for ridx in range(len(random_title_list)):\n",
    "            lstm_random_title = model(random_title_list[ridx])\n",
    "            lstm_random_body = model(random_body_list[ridx])\n",
    "            lstm_random = (lstm_random_title + lstm_random_body)/2.0\n",
    "            lstm_random_list.append(lstm_random)\n",
    "        \n",
    "        print \"done random processing..\"\n",
    "        cosine_similarity = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        score_pos = cosine_similarity(lstm_query, lstm_similar)\n",
    "\n",
    "        score_list = []\n",
    "        score_list1 = []\n",
    "        \n",
    "        score_list.append(score_pos)\n",
    "        score_list1.append(score_pos.data.numpy())\n",
    "        print \"::query random title body::\" \n",
    "        for ridx in range(len(lstm_random_list)):\n",
    "            score_neg = cosine_similarity(lstm_query, lstm_random_list[ridx])\n",
    "            score_list.append(score_neg)\n",
    "            score_list1.append(score_neg.data.numpy())\n",
    "\n",
    "        print \"::done scoring::\"\n",
    "        '''\n",
    "        diff = score_list1[0] - np.median(score_list1[1:])\n",
    "        plt.plot(diff)\n",
    "        plt.show()\n",
    "        '''\n",
    "        '''\n",
    "        X_scores = torch.stack(score_list, 1) #[batch_size, K=101]\n",
    "        y_targets = Variable(torch.zeros(X_scores.size(0)).type(torch.LongTensor)) #[batch_size]\n",
    "        loss = criterion(X_scores, y_targets) #y_target=0\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        '''\n",
    "        print \"::batch end::\"\n",
    "        #running_train_loss += loss.cpu().data[0]        \n",
    "        \n",
    "    #end for\n",
    "    #training_loss.append(running_train_loss)\n",
    "    #print \"epoch: %4d, training loss: %.4f\" %(epoch+1, running_train_loss)\n",
    "    \n",
    "    #torch.save(model, SAVE_PATH)\n",
    "#end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
